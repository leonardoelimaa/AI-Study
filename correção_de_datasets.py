# -*- coding: utf-8 -*-
"""Corre√ß√£o de Datasets

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qkZ3Ui1NUFJRnIaQXazGVcqjXVZFKKIm

## Instalar Pacotes
"""

!pip install google-generativeai pandas scikit-learn

"""## Importar Bibliotecas

"""

import google.generativeai as genai
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import ast

# Machine Learning
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report

"""## Configurar Chaves de API"""

GOOGLE_API_KEY = 'Minha API gerada pelo GOOGLE AI Studio'
genai.configure(api_key=GOOGLE_API_KEY)

"""# Case Pr√°tico: Corre√ß√£o de Dataset Desbalanceado Usando Gen AI

Somos a equipe de dados de uma fintech e nosso desafio √© construir um modelo para detectar transa√ß√µes fraudulentas. O problema √© que nosso dataset √© extremamente desbalanceado: mais de 99% das transa√ß√µes s√£o leg√≠timas. Modelos de ML cl√°ssicos sofrem para aprender com t√£o poucos exemplos de fraude.

__Nossa Estrat√©gia:__

1. Treinar um modelo baseline para provar que ele √© ruim em detectar fraudes.
2. Usar o Gemini para gerar novos dados sint√©ticos de fraude.
3. Retreinar o modelo com os dados aumentados e comprovar a melhora.

## Carregando o Dataset de Fraude
"""

#Carregando o Dataset
url_fraud = 'https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv'
df_fraud = pd.read_csv(url_fraud)

#Shape
df_fraud.shape

#Sample
df_fraud.sample(5)

"""## An√°lise Explorat√≥ria (EDA)"""

# Value Counts da variavel Class
df_fraud['Class'].value_counts()

# Normalizacao
df_fraud['Class'].value_counts(normalize=True) * 100

"""## Modelo Baseline: Treinando nos Dados Originais"""

# Regressao logistica
X = df_fraud.drop('Class', axis=1) # Variavel preditora: informa√ß√µes usadas para prever algo
y = df_fraud['Class'] # Saida: o que queremos que o modelo aprenda a prever
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

# 1. Selecionar modelo
model = LogisticRegression()

# 2. Treinar modelo
model.fit(X_train, y_train)

# 3. Fazer as predicoes
y_pred_baseline = model.predict(X_test)

# Report de classificacao
print(classification_report(y_test, y_pred_baseline))

# Matriz de confusao
sns.heatmap(confusion_matrix(y_test, y_pred_baseline), annot=True, fmt='d', cmap='Reds')

"""1. Precis√£o (Precision) A precis√£o responde √† pergunta: "De todas as vezes que o modelo previu a classe 1, quantas ele acertou?"

√â uma m√©trica de "qualidade" da previs√£o positiva. Uma alta precis√£o significa que, quando o modelo diz que √© 1, ele tem uma alta probabilidade de estar certo.

Interpreta√ß√£o: De todas as previs√µes "positivas" (classe 1) que o modelo fez, 83.6% estavam corretas.

2. Recall (Revoca√ß√£o ou Sensibilidade) O recall responde √† pergunta: "De todos os exemplos que eram realmente da classe 1, quantos o modelo conseguiu encontrar?"

√â uma m√©trica de "quantidade" ou "abrang√™ncia". Um recall alto significa que o modelo √© bom em encontrar todos os exemplos positivos existentes nos dados.

Interpreta√ß√£o: O modelo foi capaz de identificar 65.5% de todos os casos que realmente pertenciam √† classe 1. Os outros 34.5% (os 51 Falsos Negativos) n√£o foram detectados.

## Usando IA Generativa para Criar Dados Sint√©ticos
"""

# Pegando 5 exemplos de fraude do nosso dataset para mostrar ao LLM
df_fraudes_reais = X_train[y_train == 1].sample(5)

#Formatando os exemplos para o prompt (Few-Shot Prompting)
exemplos_texto = ''
#TODO Gerar exemplos
for i, row in df_fraudes_reais.iterrows():
  exemplos_texto += f'Exemplo de transa√ß√£o fraudulenta {i+1}:\n'
  exemplos_texto += str(row.to_dict()) + '\n\n'

prompt_geracao = f"""
Voc√™ √© um especialista em ci√™ncia de dados simulando dados para um modelo de detec√ß√£o de fraude.
Com base nos exemplos de transa√ß√µes fraudulentas abaixo, gere 10 novos exemplos de transa√ß√µes fict√≠cias, mas realistas, que sigam um padr√£o similar.
Retorne apenas os dicion√°rios de dados, um por linha, sem texto adicional.

{exemplos_texto}

Gere 10 novos exemplos aqui:
"""

model_gen = genai.GenerativeModel('gemini-2.5-flash')
response = model_gen.generate_content(prompt_geracao)

# Processando a resposta do LLM para transform√°-la em um DataFrame
novas_fraudes = []
for line in response.text.strip().split('\n'):
    try:
        novas_fraudes.append(ast.literal_eval(line))
    except:
        continue # Ignora linhas mal formatadas

# Criando novo DataFrame
df_novas_fraudes = pd.DataFrame(novas_fraudes)

df_novas_fraudes['Class'] = 1

df_novas_fraudes

"""## Modelo Aprimorado: Treinando com os Dados Aumentados"""

print("\n--- üöÄ Treinando nosso Modelo Aprimorado com Dados Sint√©ticos ---")
X_train_aumentado = pd.concat([X_train, df_novas_fraudes.drop('Class', axis=1)], ignore_index=True)
y_train_aumentado = pd.concat([y_train, df_novas_fraudes['Class']], ignore_index=True)

model_melhorado = LogisticRegression()
model_melhorado.fit(X_train_aumentado, y_train_aumentado)
y_pred_melhorado = model_melhorado.predict(X_test)

"""## Comparando resultados"""

print("\n--- Resultado do Modelo Baseline ---")
print(classification_report(y_test, y_pred_baseline))

print("\n--- Resultado do Modelo Aprimorado ---")
print(classification_report(y_test, y_pred_melhorado))

sns.heatmap(confusion_matrix(y_test, y_pred_baseline), annot=True, fmt='d', cmap='Reds')
plt.title('Matriz de Confus√£o - Modelo Baseline')

sns.heatmap(confusion_matrix(y_test, y_pred_melhorado), annot=True, fmt='d', cmap='Greens')
plt.title('Matriz de Confus√£o - Modelo Aprimorado com GenAI')